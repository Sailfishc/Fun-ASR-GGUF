# Fun-ASR-GGUF

将 [Fun-ASR-Nano](https://www.modelscope.cn/models/FunAudioLLM/Fun-ASR-Nano-2512) 模型转换为可以在本地高效运行的格式，实现**准确、快速的离线语音识别**，可直接转录长音频生成 SRT。主要依赖了 [llama.cpp](https://github.com/ggml-org/llama.cpp) 对 LLM Decoder 的加速推理。

### 核心特性

- ✅ **纯本地运行** - 无需网络，数据不外传
- ✅ **速度快** - 混合推理架构，支持 GPU 加速 (CUDA, Vulkan, Metal)
- ✅ **准确率高** - Encoder 保持 FP32 精度
- ✅ **内存占用小** - CTC Decoder 和 LLM Decoder 使用 INT8 量化
- ✅ **上下文增强** - 可提供上下文信息，进一步提升识别准确率
- ✅ **支持热词** - 通过 CTC 预识别，基于音素提取热词，提高专业领域识别准确率，实时监控热词文件
- ✅ **时间戳精确** - 字符级时间戳对齐
- ✅ **较长音频支持** - 单次可识别长达 60 秒的音频，超长音频自动分段，智能对齐
- ✅ **SRT 导出** - 支持自动生成美化后的 SRT 字幕

[转录速度视频演示（RTX5050）](https://github.com/user-attachments/assets/3bbd3f77-6aa9-4387-a53d-7859d1b7f5a5)

## 快速开始

### 1. 安装依赖

推理需要：

```bash
pip install -r requirements.txt
```

>  `pydub` 用于音频格式转换，需要系统安装 [ffmpeg](https://ffmpeg.org/download.html)


从 [llama.cpp Releases](https://github.com/ggml-org/llama.cpp/releases) 下载预编译二进制文件，将动态库放入 `fun_asr_gguf/bin/` 文件夹：

| 平台 | 下载文件 |
|------|----------|
| **Windows** | `llama-bXXXX-bin-win-vulkan-x64.zip` |
| **Linux** | `llama-bXXXX-bin-ubuntu-x64.zip` |
| **macOS** | `llama-bXXXX-bin-macos-arm64.zip` | 

> Linux 和 macOS 尚未经过完整测试，欢迎反馈

### 2. 下载与导出模型

#### 下载原始模型

```bash
pip install modelscope

# 模型下载后会默认存放到 ~/.cache/modelscope/hub/models/FunAudioLLM/Fun-ASR-Nano-2512 
modelscope download --model FunAudioLLM/Fun-ASR-Nano-2512 
```

#### 导出与量化流程 (6 步走)

为了获得最佳性能（GPU 加速、低显存占用），请依次执行以下脚本：

1. **导出 ONNX (FP32)**：从原始模型导出 Encoder 和 CTC 头。
   ```bash
   python 01-Export-ONNX-FP32.py
   ```
2. **算子融合优化**：对 ONNX 进行 Transformer 融合优化，显著提升 DirectML 推理速度。
   ```bash
   python 02-Optimize-ONNX.py
   ```
3. **ONNX 量化 (INT4/FP16)**：将 Encoder/CTC 量化为 INT4 权重，大幅节省显存。
   ```bash
   python 03-Quantize-ONNX.py
   ```
4. **导出 Decoder (FP16)**：提取 LLM 部分并转换为 GGUF 格式。
   ```bash
   python 04-Export-Decoder-GGUF-FP16.py
   ```
5. **Decoder 量化 (Q5_K)**：使用 `llama-quantize` 对 GGUF 进行高精度量化。
   ```bash
   python 05-Quantize-Decoder-GGUF.py
   ```
6. **运行识别测试**：验证全流程。
   ```bash
   python 06-Inference.py
   ```

---

### 3. 运行识别

```python
from fun_asr_gguf import create_asr_engine

# 创建并初始化引擎 (推荐使用单例或长期持有实例)
engine = create_asr_engine(
    encoder_onnx_path="model/Fun-ASR-Nano-Encoder-Adaptor.int4.onnx",
    ctc_onnx_path="model/Fun-ASR-Nano-CTC.int4.onnx",
    decoder_gguf_path="model/Fun-ASR-Nano-Decoder.q5_k.gguf",
    tokens_path="model/tokens.txt",
    hotwords_path="hot.txt", # 可选：热词文件路径，支持运行期间实时修改
    similar_threshold=0.6,   # 可选：热词模糊匹配阈值，默认 0.6
    max_hotwords=10,         # 可选：最多提供给 LLM 的热词数量，默认 10
)
engine.initialize()

result = engine.transcribe("audio.mp3", language="中文")
print(result.text)
```

就这么简单！

> 单段音频长度在60秒内可准确识别，过长会自动分段

---

## 工作原理

```
音频输入
    ↓
┌─────────────────────────────────────────────┐
│  Encoder (ONNX, FP32)        → 音频特征      │  保持最高精度
│  CTC Decoder (ONNX, INT8)    → 粗识别结果    │  快速预识别
└─────────────────────────────────────────────┘
    ↓              ↓              ↓
  音频特征      时间戳         热词候选
    ↓              ↓              ↓
┌─────────────────────────────────────────────┐
│  构建 Prompt (Prefix + 音频 + Suffix)        │
└─────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────┐
│  LLM Decoder (GGUF, INT8, llama.cpp)        │  支持 Vulkan GPU
│  ↓                                          │
│  生成最终识别文本                             │
└─────────────────────────────────────────────┘
    ↓
  时间戳对齐 → 输出结果
```

### 为什么这样做？

1. **CTC 预识别** 提供两样东西：
   - 粗识别结果（用于筛选热词，提供给LLM）
   - 时间戳信息（为LLM的文本输出赋予时间戳）

2. **混合架构** 各取所长：
   - ONNX Runtime：运行 Encoder 和 CTC，稳定可靠
   - llama.cpp：运行 LLM，支持 GPU 加速(Vulkan, Metal)，速度超快


### 显存占用

 - **Encoder + CTC**
   - INT4：模型 142MB，30s音频推理446MB 
 - **LLM Decoder**（约 600M 参数）
   - Q5_K：模型 431MB，2048上下文224M，推理 298MB 

 **总内存占用**（推荐 INT4 Encoder + INT4 CTC + Q5_K Decoder）：约 **1.54GB** 显存

---

## 使用示例

### 基础用法

```python
from fun_asr_gguf import create_asr_engine

engine = create_asr_engine(
    encoder_onnx_path="model/Fun-ASR-Nano-Encoder-Adaptor.int4.onnx",
    ctc_onnx_path="model/Fun-ASR-Nano-CTC.int4.onnx",
    decoder_gguf_path="model/Fun-ASR-Nano-Decoder.q5_k.gguf",
    tokens_path="model/tokens.txt",
    hotwords_path="hot.txt",  # 可选：热词文件路径
    similar_threshold=0.6,    # 可选：热词匹配阈值
    max_hotwords=10,          # 可选：最多召回热词数
)
engine.initialize()


result = engine.transcribe(
    "input.mp3", 
    language="中文", 
    context="这是睡前消息的音频，主持人叫督工", 
    verbose=True,       # 打印细节
    segment_size=60.0,  # 分片60秒
    overlap=4.0,        # 片间重叠4秒
    start_second=0.0,   # 从第零秒开始
    duration=300.0,     # 转录到第300秒结束
    srt=True            # 输出 SRT 字幕文件
)
print(result.text)           # 识别文本
print(result.segments)       # 带时间戳的分段
print(result.timings)        # 各阶段耗时
```


### 热词配置

创建 `hot.txt` 文件（每行一个热词）：

```text
督工
静静
深度学习
神经网络
```

**特性：**
1. **实时更新**：识别程序运行期间，你可以随时修改 `hot.txt` 并保存，程序会通过 `watchdog` 自动更新内存中的热词库，无需重启。
2. **模糊召回**：热词可以有几千条、上万条，程序会根据 CTC 的粗识别结果进行音素级别的模糊匹配，找出相似度在 `similar_threshold` 以上的热词，并取前 `max_hotwords` 条（默认10条）作为上下文提供给 LLM Decoder 从而得到更准确的输出。

---

## 性能参考

以下是在小新Pro16GT（U9-258H + RTX5050）笔记本上的效果，60秒的睡前消息音频，转录用时1.41秒。

需要注意的是，**LLM Decoder 所需时间取决于吐出文字的数量，不适合用 RTF 描述**，睡前消息音频的文字密度非常高，短短60秒就有350个字，但这段音频的速度可以作为下限参考，即 RTF 最慢也不会慢过 0.024

在文字密度更低的音频上，识别速度还能更快。

```
======================================================================
处理音频: input.mp3
======================================================================

[1] 加载音频...
    音频长度: 60.00s

[2] 音频编码...
    耗时: 204.58ms

[3] CTC 解码...
    CTC: 大家好二零二六年一月十一日星期日欢迎说看一千零次期世年消息请静静介绍话题去年十月十
七期节目说到韦内瑞拉问题我们回顾一下你当时的评论无论是从集结的兵力来看还是从动极来看特朗普
对维伦瑞拉政权发动全面的进攻最多是发动象征性轰炸进行政制投击在诺倍尔和平讲发给了韦内瑞拉反
军队进攻的概率进一步降低现在美国突袭韦内瑞拉抓走了总统马度罗都工你怎么看待两个月之前的判断
遍美国对于韦伦瑞拉的突袭性质依然是政治投击不能算是地面战争入期的美国军队总数是以两百站在韦
上的时间不超过一个小时算是地面战争或者全面进攻实在有点勉强当然美国东用总力量并小一五十架先
累约不止的情报网络这放在东亚或者欧洲也不是一支很小的力量用到美国的西半球主场压倒韦伦瑞拉的
的
    热词: ['督工', '睡前消息']
    耗时: 83.34ms (Infer: 52ms, Dec: 1ms, HW: 30ms)

[4] 准备 Prompt...
--------------- Prefix Prompt ---------------
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
请结合上下文信息，更加准确地完成语音转写任务。


**上下文信息：**这是1004期睡前消息节目，主持人叫督工，助理叫静静


----------------------------------------
    Prefix: 73 tokens
    Suffix: 5 tokens

[5] LLM 解码...
======================================================================
大家好，2026年1月11日，星期日，欢迎收看1004期睡前消息，请静静介绍话题。去年10月19日，967期
节目说到委内瑞拉问题，我们回顾一下你当时的评论。无论是从集中的兵力来看，还是从动机来看，特
朗普政府并不打算对委内瑞拉政权发动全面的进攻，最多是发动象征性的轰炸，甚至投机在诺贝尔和平
奖发给了委内瑞拉反对派之后，美国军队进攻的概率进一步降低。现在美国突袭委内瑞拉，抓走了总统
马杜罗。督工你怎么看待两个月之前的判断？当初的判断不变：美国对于委内瑞拉的突袭性质依然是政
治投机，不能算是地面战争。入侵的美国军队总数是以200占在委内瑞拉领土上的时间不超过1个小时，
算是地面战争或者全面进攻，实在有点勉强。当然，美国动用总力量并不小，150架先进飞机加上经年 
累月部署的情报网络，这放在东亚或者欧洲也不是一枝很小的力量，用到美国的西半球主场压倒委内瑞
拉的军队那是必然的。

======================================================================

[6] 时间戳对齐
    对齐耗时: 124.49ms
    结果预览: 大(1.02s) 家(1.14s) 好(1.26s) ，(1.41s) 2(1.56s) 0(1.68s) 2(1.80s) 6(1.92s) 
年(2.04s) 1(2.22s) ...

[统计]
  音频长度:  60.00s
  Decoder输入:  15749 tokens/s (总: 204, prefix:73, audio:126, suffix:5)
  Decoder输出:    259 tokens/s (总: 254)

[转录耗时]
  - 音频编码：   205ms
  - CTC解码：     83ms (Infer: 52ms, Dec: 1ms, HW: 30ms)
  - Prompt:        1ms
  - LLM读取：     13ms
  - LLM生成：    981ms
  - 时间对齐：   124ms
  - 推理总计：  1.41s
```

同一段音频，纯 CPU 推理速度：

```
[统计]
  音频长度:  60.00s
  Decoder输入:    496 tokens/s (总: 204, prefix:73, audio:126, suffix:5)
  Decoder输出:     61 tokens/s (总: 251)

[转录耗时]
  - 音频编码：   749ms
  - CTC解码：    152ms (Infer: 121ms, Dec: 1ms, HW: 30ms)
  - Prompt:        1ms
  - LLM读取：    411ms
  - LLM生成：   4106ms
  - 时间对齐：   174ms
  - 推理总计：  5.60s
```

长音频推理输出示例：

```
======================================================================
处理音频: input500.mp3
======================================================================

[1] 加载音频...
    音频长度: 300.00s
    检测到长音频，开启分段识别模式...
[1/6]
--- 处理分段 [0.0s - 60.0s] ---
大家好，2026年1月17日星期日，欢迎收看1004期睡前消息，请静静介绍话题。去年10月967期节目说到
委内瑞拉问题，我们回顾一下你当时的评论，无论是从集结的兵力来看，还是从动机来看，特朗普政府
并不打算对委内瑞拉政权发动全面的进攻，最多是发动效能型的轰炸进行政治投机。在诺贝尔和平奖发
给了委内瑞拉反对派之后，美国军队进攻的概率进一步降低。现在美国突袭委内瑞拉，抓走了总统马杜
罗。杜工，你怎么看待两个月之前的判断？当初的判断不变，美国对于委内瑞拉的突袭性质依然是政治
投机，不能算是地面战争。入侵的美国军队总数是100%站在委内瑞拉领土上的时间不超过一个小时，算
是地面战争或者全面进攻，比较有点勉强。当然，美国动用总力量并不小，150架先进飞机，加上经年
累月布置的情报网络，这放在东亚。
[2/6] 
--- 处理分段 [56.0s - 116.0s] ---
一架先进飞机，加上经年累月部署的情报网络，这放在东亚或者欧洲也不是一针很小的力量。用到美国
的西半球主场压倒委内瑞拉的军队那是必然的。但就算是在西半球，对小国动手，从美国之前的案例来
看，战争的代价还是不能忽视。比如说1989年，美国进攻250万人口的巴拿马，抓到总统诺雷加，美国
军队出动了2万人，当场死掉23人，受伤300多人。再往前说，1983年进攻格林纳达，当地人口10万人，
美国派出1万人登陆，也是战死了19人，受伤过百。委内瑞拉的人口差不多3000万，军队12万人，防空
系统包括了12套S300系统。这放到乌克兰战场上，也是一支能够改变局势的战略性力量。按照常理来说
，美国境内抓总统，死亡2000，伤亡7000，那是起码的数字。但是美国军队一个人没死，只有7个人受
伤，其中两个人需要住院，另外5个人已经重新回到单位上班了。这说明美国入侵委内瑞拉的一小时行
动还是第960次。
[3/6] 
--- 处理分段 [112.0s - 172.0s] ---
这说明美国入侵委内瑞拉的一小时行动还是第967期节目定义的政治投机。从委内瑞拉方面的反应来看
，马杜罗被抓走也不能算是战争。当年巴拿马诺雷加总统谁都知道他是一个现实水平的毒贩子，在美国
进攻之前几个月，他刚刚废除了选举出来的总统，自己当军事独裁者。但是虽然诺雷加自己在突袭的第
一时间就放弃了指挥，但是他的军队进行了认真反击。正规军在机场伏击美国的空降兵，在最后还有一
个民兵营在城区进行了两轮游击，迫使美国从本土调集了2000援军。这里要顺便说一下1959年古巴革命
之后第一次输出革命就是对巴拿马派兵，只是也被巴拿马军队打败了，全体投降，遣返古巴。格林纳达
抵抗美国的条件和委内瑞拉有点像，正面杀死了总理兼革命领袖毕小普，然后剩下的人依靠古巴军队做
主战，抵抗美国入侵。这里首先杀领袖的是亲苏联的反清派，其次除了古巴。
[4/6] 
--- 处理分段 [168.0s - 228.0s] ---
首先，杀领袖的是亲苏联的强硬派；其次，除了古巴军队，十个十万人的小国也能组织正规反击。防空
火力给美国留下了深刻印象，和委内瑞拉唯一的区别就是人口规模。和巴拿马或者格陵娜达相比，委内
瑞拉总统府被拿下了，只有古巴卫队死战到底。其他的委内瑞拉人负责围观。这说明古巴军队的核心问
题是政治信心已经崩溃了，让特朗普发现了政治投机的机会。就算美国不发动进攻，马杜罗政权靠古巴
军队保护自己，也已经是一个骇人听闻的大问题。这说明他的危险的时候，除了自己的老婆，并不信任
本国公民，甚至不信任任何一部分本国公民。马杜罗统治集团的国内政治资产是负数。对比一下俄罗斯
入侵乌克兰的第一个星期，泽连斯基下令给首都市民发枪，最危急的时刻就是靠20000临时动员的民兵
打退了俄国的空降旅。毛主席说：‘军队必须讲政治’，反过来说：‘
[5/6] 
--- 处理分段 [224.0s - 284.0s] ---
毛主席说，军队必须讲政治。反过来说，政治资产为负数的领导人没有资格使用军事力量。特朗普发起
军事行动没有什么心理压力，但是他的国内政治余热也不算多，必须省着用。最新消息是，美国参议院
发起决议，制止了特朗普对委内瑞拉发动新的军事进攻。好几个共和党议员也站在民主党一边反对特朗
普。所以我说，特朗普先是通过情报评估了马杜罗的政治资本，然后用商人的方式发起了政治投机。如
果马杜罗的政治资本能够比毒贩的洛雷加稍微强一点，或者比10万人的小国格林纳达强一点，特朗普是
不敢投机的。伊朗的神权政府最近也遇到麻烦了，全国所有城市都出现游行示威。最新消息是部分边界
城市脱离政府掌控，神权政府切断了全国互联网。督工，你怎么怎么看伊朗当前的局势？过去十几年，
伊朗至少有四次全国性的抗议升级到暴动水平，其中至少有两次全国切断了互联网。仅从规模来看，伊
朗这次全国性的抗议行动并不比。
[6/6]
--- 处理分段 [280.0s - 300.0s] ---
互联网仅从规模来看，伊朗这次全国性的抗议行动并不比前几次更严重。但是首先，矛盾会一次次积累
，从全国性暴动的爆发频率来看，开始还有七八年的间隔，现在已经两三年就要来一场。其次，伊朗统
治集团最近的实力和信心都受到打击，所以伊朗的神权政府确实有灭亡的危机。

[转录耗时]
  - 音频编码：  1267ms
  - CTC解码：    466ms (Infer: 320ms, Dec: 7ms, HW: 139ms)
  - Prompt:        7ms
  - LLM读取：     56ms
  - LLM生成：   4844ms
  - 时间对齐：   562ms
  - 推理总计：  7.21s

✓ 字幕已导出至: input500.srt

------------------------------ 完整转录文本 ------------------------------
大家好，2026年1月17日星期日，欢迎收看1004期睡前消息，请静静介绍话题。去年10月967期节目说到
委内瑞拉问题，我们回顾一下你当时的评论，无论是从集结的兵力来看，还是从动机来看，特朗普政府
并不打算对委内瑞拉政权发动全面的进攻，最多是发动效能型的轰炸进行政治投机。在诺贝尔和平奖发
给了委内瑞拉反对派之后，美国军队进攻的概率进一步降低。现在美国突袭委内瑞拉，抓走了总统马杜
罗。杜工，你怎么看待两个月之前的判断？当初的判断不变，美国对于委内瑞拉的突袭性质依然是政治
投机，不能算是地面战争。入侵的美国军队总数是100%站在委内瑞拉领土上的时间不超过一个小时，算
是地面战争或者全面进攻，比较有点勉强。当然，美国动用总力量并不小，150架先进飞机，加上经年 
累月部署的情报网络，这放在东亚或者欧洲也不是一针很小的力量。用到美国的西半球主场压倒委内瑞
拉的军队那是必然的。但就算是在西半球，对小国动手，从美国之前的案例来看，战争的代价还是不能
忽视。比如说1989年，美国进攻250万人口的巴拿马，抓到总统诺雷加，美国军队出动了2万人，当场死
掉23人，受伤300多人。再往前说，1983年进攻格林纳达，当地人口10万人，美国派出1万人登陆，也是
战死了19人，受伤过百。委内瑞拉的人口差不多3000万，军队12万人，防空系统包括了12套S300系统。
这放到乌克兰战场上，也是一支能够改变局势的战略性力量。按照常理来说，美国境内抓总统，死亡2000，伤亡7000，那是起码的数字。但是美国军队一个人没死，只有7个人受伤，其中两个人需要住院， 
另外5个人已经重新回到单位上班了。这说明美国入侵委内瑞拉的一小时行动还是第967期节目定义的政
治投机。从委内瑞拉方面的反应来看，马杜罗被抓走也不能算是战争。当年巴拿马诺雷加总统谁都知道
他是一个现实水平的毒贩子，在美国进攻之前几个月，他刚刚废除了选举出来的总统，自己当军事独裁
者。但是虽然诺雷加自己在突袭的第一时间就放弃了指挥，但是他的军队进行了认真反击。正规军在机
场伏击美国的空降兵，在最后还有一个民兵营在城区进行了两轮游击，迫使美国从本土调集了2000援军
。这里要顺便说一下1959年古巴革命之后第一次输出革命就是对巴拿马派兵，只是也被巴拿马军队打败
了，全体投降，遣返古巴。格林纳达抵抗美国的条件和委内瑞拉有点像，正面杀死了总理兼革命领袖毕
小普，然后剩下的人依靠古巴军队做主战，抵抗美国入侵。这里首先杀领袖的是亲苏联的强硬派；其次
，除了古巴军队，十个十万人的小国也能组织正规反击。防空火力给美国留下了深刻印象，和委内瑞拉
唯一的区别就是人口规模。和巴拿马或者格陵娜达相比，委内瑞拉总统府被拿下了，只有古巴卫队死战
到底。其他的委内瑞拉人负责围观。这说明古巴军队的核心问题是政治信心已经崩溃了，让特朗普发现
了政治投机的机会。就算美国不发动进攻，马杜罗政权靠古巴军队保护自己，也已经是一个骇人听闻的
大问题。这说明他的危险的时候，除了自己的老婆，并不信任本国公民，甚至不信任任何一部分本国公
民。马杜罗统治集团的国内政治资产是负数。对比一下俄罗斯入侵乌克兰的第一个星期，泽连斯基下令
给首都市民发枪，最危急的时刻就是靠20000临时动员的民兵打退了俄国的空降旅。毛主席说：‘军队必
须讲政治。反过来说，政治资产为负数的领导人没有资格使用军事力量。特朗普发起军事行动没有什么
心理压力，但是他的国内政治余热也不算多，必须省着用。最新消息是，美国参议院发起决议，制止了
特朗普对委内瑞拉发动新的军事进攻。好几个共和党议员也站在民主党一边反对特朗普。所以我说，特
朗普先是通过情报评估了马杜罗的政治资本，然后用商人的方式发起了政治投机。如果马杜罗的政治资
本能够比毒贩的洛雷加稍微强一点，或者比10万人的小国格林纳达强一点，特朗普是不敢投机的。伊朗
的神权政府最近也遇到麻烦了，全国所有城市都出现游行示威。最新消息是部分边界城市脱离政府掌控
，神权政府切断了全国互联网。督工，你怎么怎么看伊朗当前的局势？过去十几年，伊朗至少有四次全
国性的抗议升级到暴动水平，其中至少有两次全国切断了互联网。仅从规模来看，伊朗这次全国性的抗
议行动并不比前几次更严重。但是首先，矛盾会一次次积累，从全国性暴动的爆发频率来看，开始还有
七八年的间隔，现在已经两三年就要来一场。其次，伊朗统治集团最近的实力和信心都受到打击，所以
伊朗的神权政府确实有灭亡的危机。
--------------------------------------------------------------------------
```

---

## 常见问题

**Q: Encoder 和 CTC 如何选择量化精度？**  
- Encoder-Adapter 以及 CTC Decoder 都是在用 onnxruntime 加速，它既支持 CPU，也支持通过 DirectML 使用显卡加速。CPU 跑 int4 最快，GPU 跑 fp16 最快，但出于省显存角度，DirectML 跑 int4 更好。


**Q: 支持哪些语言？**  
- Fun-ASR-Nano-2512 支持中文、英文、日文。
- Fun-ASR-MLT-Nano-2512 还支持更多语言（粤语、韩文、越南语等）。

**Q: 如何提高识别准确率？**  
- 配置 `hot.txt` 添加领域热词
- 使用 `context` 参数提供上下文信息

**Q: 输出全是「!!!!!!!!!!」怎么办？**  
- Intel 集成显卡的 fp16 矩阵求和计算没有使用 fp32 做临时变量，溢出为 NaN，产生了如此问题，解决办法是通过设置环境变量禁用 fp32 ，或禁用 vulkan。取决于 CPU 更快，还是集显的 fp32 更快。

```python
os.environ["VK_ICD_FILENAMES"] = "none"       # 禁止 Vulkan
os.environ["GGML_VK_VISIBLE_DEVICES"] = "0"   # 禁止 Vulkan 用独显（强制用集显）
os.environ["GGML_VK_DISABLE_F16"] = "1"       # 禁止 VulkanFP16 计算（Intel集显fp16有溢出问题）
```



---

## 文件说明

### 项目结构

- `01-Export-ONNX-FP32.py` - 导出原始 ONNX
- `02-Optimize-ONNX.py` - 优化算子融合
- `03-Quantize-ONNX.py` - 量化 ONNX (INT4)
- `04-Export-Decoder-GGUF-FP16.py` - 导出 GGUF
- `05-Quantize-Decoder-GGUF-Q4_K.py` - GGUF 高级量化
- `06-Inference.py` - 完整推理示例
- `fun_asr_gguf/`
  - `core/` - 核心逻辑（资源管理、解码、编排）
  - `bin/` - 存放 DLL 和二进制可执行文件
  - `asr_engine.py` - Facade 入口类
  - `srt_utils.py` - 字幕生成工具
  - `text_merge.py` - 滑动窗口文本合并算法

### 导出的模型

```
model/
├── Fun-ASR-Nano-Encoder-Adaptor.int4.onnx   # 音频编码器 (INT4, 推荐)
├── Fun-ASR-Nano-CTC.int4.onnx               # CTC 解码器 (INT4)
├── Fun-ASR-Nano-Decoder.q5_k.gguf           # LLM 解码器 (Q5_K, 推荐)
└── tokens.txt                               # CTC Token 映射
```

---

## 技术细节

### 架构设计

- **Encoder**：ONNX 格式，INT4 量化，提取音频特征
- **CTC Decoder**：ONNX 格式，INT4 量化，用于时间戳和热词候选
- **LLM Decoder**：GGUF 格式，Q5_K 量化，llama.cpp 推理


---

## 致谢

- [Fun-ASR](https://github.com/FunAudioLLM/Fun-ASR) - 原始模型
- [llama.cpp](https://github.com/ggml-org/llama.cpp) - GGUF 推理引擎
